{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pys import credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Deploying StorageAccount with name handmadestorage822b6e018.\n",
      "Deploying AppInsights with name handmadeinsights4f9e508a.\n",
      "Deployed AppInsights with name handmadeinsights4f9e508a. Took 4.13 seconds.\n",
      "Deploying KeyVault with name handmadekeyvault0f212c84.\n",
      "Deployed KeyVault with name handmadekeyvault0f212c84. Took 18.55 seconds.\n",
      "Deploying Workspace with name handmade_ntt_data_challenge.\n",
      "Deployed StorageAccount with name handmadestorage822b6e018. Took 23.62 seconds.\n",
      "Deployed Workspace with name handmade_ntt_data_challenge. Took 35.61 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Workspace\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name                  = \"handmade_ntt_data_challenge\",\n",
    "                      subscription_id       = credentials.azure_subscription_id,\n",
    "                      resource_group        = credentials.azure_resource_group,\n",
    "                      create_resource_group = False,\n",
    "                      location              = credentials.azure_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Workspace\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace(workspace_name        = \"handmade_ntt_data_challenge\",\n",
    "               subscription_id       = credentials.azure_subscription_id,\n",
    "               resource_group        = credentials.azure_resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model handmade_model\n"
     ]
    }
   ],
   "source": [
    "# Register the model\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace  = ws, \n",
    "                       model_path = \"../resources/model.pkl\", \n",
    "                       model_name = \"handmade_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model handmade_x_scaler\n"
     ]
    }
   ],
   "source": [
    "# Register the x_scaler\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace  = ws, \n",
    "                       model_path = \"../resources/x_scaler.pkl\", \n",
    "                       model_name = \"handmade_x_scaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inference config\n",
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name = \"handmade_env\")\n",
    "dummy_inference_config = InferenceConfig(environment      = env,\n",
    "                                         source_directory = \"../pys/\",\n",
    "                                         entry_script     = \"../pys/score.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local deployment\n",
    "\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_2419/428816697.py:1: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(workspace         = ws,\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Models must either be of type azureml.core.model.Model or a str path to a file or folder.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_2419/428816697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m service = Model.deploy(workspace         = ws,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0mname\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0;34m\"handmade-predict\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mmodels\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0minference_config\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdummy_inference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mdeployment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \u001b[0;31m# Local webservice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment_config\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocalWebserviceDeploymentConfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m             return deployment_config._webservice_type._deploy(workspace, name, models,\n\u001b[0m\u001b[1;32m   1664\u001b[0m                                                               \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m                                                               deployment_config=deployment_config)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36m_deploy\u001b[0;34m(workspace, name, models, image_config, deployment_config, wait, inference_config)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         service.update(models=models,\n\u001b[0m\u001b[1;32m    740\u001b[0m                        \u001b[0mimage_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                        \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     71\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, models, image_config, deployment_config, wait, inference_config)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_identify_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36m_identify_models\u001b[0;34m(workspace, models)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 raise NotImplementedError('Models must either be of type azureml.core.model.Model or a str '\n\u001b[0m\u001b[1;32m    930\u001b[0m                                           'path to a file or folder.')\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Models must either be of type azureml.core.model.Model or a str path to a file or folder."
     ]
    }
   ],
   "source": [
    "service = Model.deploy(workspace         = ws,\n",
    "                       name              = \"handmade-predict\",\n",
    "                       models            = [model],\n",
    "                       inference_config  = dummy_inference_config,\n",
    "                       deployment_config = deployment_config,\n",
    "                       overwrite         = True)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud deployment\n",
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment.from_conda_specification(name='cloudenv', file_path=\"../resources/conda.yaml\")\n",
    "\n",
    "inference_config = InferenceConfig(environment=env, source_directory='../pys/', entry_script='../pys/score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_29699/652748521.py:6: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(workspace         = ws,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model handmade_model:2 to /var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/azureml_9w02hnkt/handmade_model/2\n",
      "Downloading model handmade_x_scaler:1 to /var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/azureml_9w02hnkt/handmade_x_scaler/1\n",
      "Generating Docker build context.\n",
      "2023/03/28 07:24:11 Downloading source code...\n",
      "2023/03/28 07:24:12 Finished downloading source code\n",
      "2023/03/28 07:24:12 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2023/03/28 07:24:12 Successfully set up Docker network: acb_default_network\n",
      "2023/03/28 07:24:12 Setting up Docker configuration...\n",
      "2023/03/28 07:24:13 Successfully set up Docker configuration\n",
      "2023/03/28 07:24:13 Logging in to registry: e4e0e96ebb3f40cdb53da54690e88f94.azurecr.io\n",
      "2023/03/28 07:24:14 Successfully logged into e4e0e96ebb3f40cdb53da54690e88f94.azurecr.io\n",
      "2023/03/28 07:24:14 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/03/28 07:24:14 Scanning for dependencies...\n",
      "2023/03/28 07:24:14 Successfully scanned dependencies\n",
      "2023/03/28 07:24:14 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  71.68kB\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1@sha256:5d24ccb3c12cd77f7c9ab1f8d748500964519d984d7b22648055f331d442cbad\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1@sha256:5d24ccb3c12cd77f7c9ab1f8d748500964519d984d7b22648055f331d442cbad: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
      "846c0b181fff: Pulling fs layer\n",
      "5f09fa44f56d: Pulling fs layer\n",
      "a8568155e18a: Pulling fs layer\n",
      "3a837bb9a3e8: Pulling fs layer\n",
      "29773c5290d6: Pulling fs layer\n",
      "6aa04504f3c7: Pulling fs layer\n",
      "4cd538338c63: Pulling fs layer\n",
      "554cc2a21ea1: Pulling fs layer\n",
      "cf179dcebf06: Pulling fs layer\n",
      "9a6d8b020993: Pulling fs layer\n",
      "3a837bb9a3e8: Waiting\n",
      "4cd538338c63: Waiting\n",
      "554cc2a21ea1: Waiting\n",
      "cf179dcebf06: Waiting\n",
      "9a6d8b020993: Waiting\n",
      "29773c5290d6: Waiting\n",
      "6aa04504f3c7: Waiting\n",
      "846c0b181fff: Verifying Checksum\n",
      "846c0b181fff: Download complete\n",
      "a8568155e18a: Verifying Checksum\n",
      "a8568155e18a: Download complete\n",
      "3a837bb9a3e8: Verifying Checksum\n",
      "3a837bb9a3e8: Download complete\n",
      "29773c5290d6: Verifying Checksum\n",
      "29773c5290d6: Download complete\n",
      "4cd538338c63: Verifying Checksum\n",
      "4cd538338c63: Download complete\n",
      "554cc2a21ea1: Verifying Checksum\n",
      "554cc2a21ea1: Download complete\n",
      "6aa04504f3c7: Verifying Checksum\n",
      "6aa04504f3c7: Download complete\n",
      "cf179dcebf06: Verifying Checksum\n",
      "cf179dcebf06: Download complete\n",
      "9a6d8b020993: Verifying Checksum\n",
      "9a6d8b020993: Download complete\n",
      "5f09fa44f56d: Verifying Checksum\n",
      "5f09fa44f56d: Download complete\n",
      "846c0b181fff: Pull complete\n",
      "5f09fa44f56d: Pull complete\n",
      "a8568155e18a: Pull complete\n",
      "3a837bb9a3e8: Pull complete\n",
      "29773c5290d6: Pull complete\n",
      "6aa04504f3c7: Pull complete\n",
      "4cd538338c63: Pull complete\n",
      "554cc2a21ea1: Pull complete\n",
      "cf179dcebf06: Pull complete\n",
      "9a6d8b020993: Pull complete\n",
      "Digest: sha256:5d24ccb3c12cd77f7c9ab1f8d748500964519d984d7b22648055f331d442cbad\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1@sha256:5d24ccb3c12cd77f7c9ab1f8d748500964519d984d7b22648055f331d442cbad\n",
      " ---> 3c4c69811b78\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 73608f4959fc\n",
      "Removing intermediate container 73608f4959fc\n",
      " ---> 28ab9f64cfa2\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 11ad088c6c61\n",
      "Removing intermediate container 11ad088c6c61\n",
      " ---> 32709d22929f\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in 8adc899972d6\n",
      "Removing intermediate container 8adc899972d6\n",
      " ---> 028a96d372dd\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> e3252970b21e\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in a29db2cf4a69\n",
      "Removing intermediate container a29db2cf4a69\n",
      " ---> de534d4bbbeb\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 9b3fefb856d9\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d5f6482c51f5b5a8eac96ca050cb2b23 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 757a56ccefab\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (repodata.json): ...working... \n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model(ws, \"handmade_model\")\n",
    "scaler = Model(ws, \"handmade_x_scaler\")\n",
    "\n",
    "service = Model.deploy(workspace         = ws,\n",
    "                       name              = \"handmade-predict\",\n",
    "                       models            = [model, scaler],\n",
    "                       inference_config  = inference_config,\n",
    "                       deployment_config = deployment_config,\n",
    "                       overwrite         = True)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'edad': 40.0, 'trabajo': 40.0, 'deuda': 40.0, 'saldo': 40.0, 'vivienda': 40.0, 'prestamo': 40.0, 'duracion': 40.0, 'fecha_contacto': 40.0, 'campaign': 40.0, 'tiempo_transcurrido': 40.0, 'contactos_anteriores': 40.0, 'target': 40.0, 'contactado': 40.0, 'desconocido': 40.0, 'fijo': 40.0, 'movil': 40.0, 'casado': 40.0, 'divorciado': 40.0, 'soltero': 40.0, 'exito': 40.0, 'nuevo_cliente': 40.0, 'otro': 40.0, 'sin_exito': 0, 'primaria': 1, 'secundaria/superiores': 0, 'universitarios': 40.0}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://localhost:6789\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "        \"edad\": 40.0,\n",
    "        \"trabajo\": 40.0,\n",
    "        \"deuda\": 40.0,\n",
    "        \"saldo\": 40.0,\n",
    "        \"vivienda\": 40.0,\n",
    "        \"prestamo\": 40.0,\n",
    "        \"duracion\": 40.0,\n",
    "        \"fecha_contacto\": 40.0,\n",
    "        \"campaign\": 40.0,\n",
    "        \"tiempo_transcurrido\": 40.0,\n",
    "        \"contactos_anteriores\": 40.0,\n",
    "        \"target\": 40.0,\n",
    "        \"contactado\": 40.0,\n",
    "        \"desconocido\": 40.0,\n",
    "        \"fijo\": 40.0,\n",
    "        \"movil\": 40.0,\n",
    "        \"casado\": 40.0,\n",
    "        \"divorciado\": 40.0,\n",
    "        \"soltero\": 40.0,\n",
    "        \"exito\": 40.0,\n",
    "        \"nuevo_cliente\": 40.0,\n",
    "        \"otro\": 40.0,\n",
    "        \"sin_exito\": 0,\n",
    "        \"primaria\": 1,\n",
    "        \"secundaria/superiores\": 0,\n",
    "        \"universitarios\": 40.0\n",
    "      }\n",
    "\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
